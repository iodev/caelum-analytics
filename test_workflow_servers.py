#!/usr/bin/env python3
"""
Comprehensive test suite for 5-workflow architecture MCP servers
"""

import sys
import asyncio
import json
from pathlib import Path
import importlib.util
from typing import Dict, Any, List

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

def test_import_all_servers():
    """Test that all workflow servers can be imported without errors"""
    print("üß™ Testing server imports...")
    
    try:
        from caelum_analytics.workflow_servers import (
            DevelopmentWorkflowServer,
            BusinessWorkflowServer,
            InfrastructureWorkflowServer,
            CommunicationWorkflowServer,
            SecurityWorkflowServer
        )
        print("‚úÖ All workflow servers imported successfully")
        return True
    except Exception as e:
        print(f"‚ùå Import error: {e}")
        return False

def test_server_initialization():
    """Test server initialization without MCP dependencies"""
    print("\nüß™ Testing server initialization...")
    
    try:
        from caelum_analytics.workflow_servers.development.server import DevelopmentWorkflowServer
        from caelum_analytics.workflow_servers.business.server import BusinessWorkflowServer
        from caelum_analytics.workflow_servers.infrastructure.server import InfrastructureWorkflowServer
        from caelum_analytics.workflow_servers.communication.server import CommunicationWorkflowServer
        from caelum_analytics.workflow_servers.security.server import SecurityWorkflowServer
        
        servers = [
            ("Development", DevelopmentWorkflowServer),
            ("Business", BusinessWorkflowServer),
            ("Infrastructure", InfrastructureWorkflowServer),
            ("Communication", CommunicationWorkflowServer),
            ("Security", SecurityWorkflowServer)
        ]
        
        for name, ServerClass in servers:
            try:
                server = ServerClass()
                print(f"‚úÖ {name} workflow server initialized")
                
                # Test that all_tools is populated
                if hasattr(server, 'all_tools') and server.all_tools:
                    print(f"   üìä {len(server.all_tools)} tools registered")
                else:
                    print(f"   ‚ö†Ô∏è  No tools found in {name} server")
                    
            except Exception as e:
                print(f"‚ùå {name} server initialization failed: {e}")
                return False
                
        return True
    except Exception as e:
        print(f"‚ùå Server initialization error: {e}")
        return False

def test_tool_definitions():
    """Test that tool definitions are properly structured"""
    print("\nüß™ Testing tool definitions...")
    
    try:
        from caelum_analytics.workflow_servers.development.server import DevelopmentWorkflowServer
        
        server = DevelopmentWorkflowServer()
        
        required_fields = ["name", "description", "priority", "category", "intents", "underlying_service", "schema"]
        
        for tool_name, tool_def in server.all_tools.items():
            for field in required_fields:
                if field not in tool_def:
                    print(f"‚ùå Tool {tool_name} missing field: {field}")
                    return False
                    
            # Test schema structure
            schema = tool_def["schema"]
            if "type" not in schema:
                print(f"‚ùå Tool {tool_name} schema missing type")
                return False
                
        print(f"‚úÖ All {len(server.all_tools)} development tools properly defined")
        return True
        
    except Exception as e:
        print(f"‚ùå Tool definition test error: {e}")
        return False

async def test_tool_execution():
    """Test tool execution logic"""
    print("\nüß™ Testing tool execution...")
    
    try:
        from caelum_analytics.workflow_servers.development.server import DevelopmentWorkflowServer
        
        server = DevelopmentWorkflowServer()
        
        # Test analyze_code_quality tool
        result = await server.execute_tool("analyze_code_quality", {
            "code": "print('hello world')",
            "language": "python"
        })
        
        if "analysis_type" in result and "findings" in result:
            print("‚úÖ Development tool execution working")
        else:
            print(f"‚ùå Unexpected tool result: {result}")
            return False
            
        return True
        
    except Exception as e:
        print(f"‚ùå Tool execution test error: {e}")
        return False

async def test_tool_selection():
    """Test intelligent tool selection"""
    print("\nüß™ Testing intelligent tool selection...")
    
    try:
        from caelum_analytics.workflow_servers.development.server import DevelopmentWorkflowServer
        
        server = DevelopmentWorkflowServer()
        
        # Test with security-focused query
        selected = await server.select_tools_for_context("analyze security vulnerabilities in my code", max_tools=5)
        
        if len(selected) > 0:
            print(f"‚úÖ Tool selection working - selected {len(selected)} tools")
            for tool_name in list(selected.keys())[:3]:
                print(f"   üîß {tool_name}")
        else:
            print("‚ùå No tools selected")
            return False
            
        return True
        
    except Exception as e:
        print(f"‚ùå Tool selection test error: {e}")
        return False

async def test_dynamic_explorer():
    """Test dynamic server explorer"""
    print("\nüß™ Testing dynamic server explorer...")
    
    try:
        from caelum_analytics.dynamic_server_explorer import dynamic_explorer
        
        # Test initialization
        await dynamic_explorer.initialize()
        
        if len(dynamic_explorer.servers) > 0:
            print(f"‚úÖ Dynamic explorer initialized - {len(dynamic_explorer.servers)} servers")
        else:
            print("‚ùå No servers found in explorer")
            return False
            
        # Test hierarchy generation
        hierarchy = dynamic_explorer.get_server_hierarchy()
        
        if "workflow_servers" in hierarchy and "summary" in hierarchy:
            print("‚úÖ Server hierarchy generation working")
        else:
            print("‚ùå Hierarchy generation failed")
            return False
            
        # Test search
        search_results = dynamic_explorer.search_by_capability("analysis")
        
        if len(search_results["servers"]) > 0 or len(search_results["tools"]) > 0:
            print("‚úÖ Capability search working")
        else:
            print("‚ùå Search functionality failed")
            return False
            
        return True
        
    except Exception as e:
        print(f"‚ùå Dynamic explorer test error: {e}")
        return False

def test_claude_config():
    """Test Claude configuration file"""
    print("\nüß™ Testing Claude configuration...")
    
    try:
        config_path = Path("claude_config_5workflow_optimized.json")
        
        if not config_path.exists():
            print("‚ùå Optimized Claude config not found")
            return False
            
        with open(config_path) as f:
            config = json.load(f)
            
        if "mcpServers" not in config:
            print("‚ùå Invalid Claude config structure")
            return False
            
        workflow_servers = [
            "caelum-development-workflow",
            "caelum-business-workflow", 
            "caelum-infrastructure-workflow",
            "caelum-communication-workflow",
            "caelum-security-workflow"
        ]
        
        found_servers = 0
        for server in workflow_servers:
            if server in config["mcpServers"]:
                found_servers += 1
                print(f"   ‚úÖ {server} configured")
            else:
                print(f"   ‚ùå {server} missing from config")
                
        if found_servers == len(workflow_servers):
            print(f"‚úÖ All {found_servers} workflow servers in Claude config")
            return True
        else:
            print(f"‚ùå Only {found_servers}/{len(workflow_servers)} workflow servers configured")
            return False
            
    except Exception as e:
        print(f"‚ùå Claude config test error: {e}")
        return False

async def test_pre_hook_system():
    """Test the pre-hook system for external LLMs"""
    print("\nüß™ Testing pre-hook system...")
    
    try:
        from caelum_analytics.tool_prescreener import tool_prescreener
        from caelum_analytics.llm_prehook import llm_prehook
        
        # Test tool prescreener initialization
        await tool_prescreener.initialize_tool_registry()
        
        if len(tool_prescreener.tool_registry) > 0:
            print(f"‚úÖ Tool prescreener initialized - {len(tool_prescreener.tool_registry)} tools registered")
        else:
            print("‚ùå Tool prescreener failed to initialize")
            return False
            
        # Test query analysis
        query = "analyze the security of my Python application"
        analysis = await tool_prescreener.analyze_query(query)
        
        if analysis.intent and analysis.complexity:
            print(f"‚úÖ Query analysis working - Intent: {analysis.intent}, Complexity: {analysis.complexity}")
        else:
            print("‚ùå Query analysis failed")
            return False
            
        # Test tool pre-screening
        selected_tools = await tool_prescreener.prescreen_tools(query)
        
        if len(selected_tools) <= 100:  # GitHub Copilot limit
            print(f"‚úÖ Tool pre-screening working - {len(selected_tools)} tools (under GitHub Copilot limit)")
            return True
        else:
            print(f"‚ùå Too many tools selected: {len(selected_tools)} (exceeds limit)")
            return False
            
    except Exception as e:
        print(f"‚ùå Pre-hook system test error: {e}")
        return False

async def run_all_tests():
    """Run all tests and provide summary"""
    print("üöÄ Starting comprehensive 5-workflow architecture tests...\n")
    
    tests = [
        ("Import Tests", test_import_all_servers),
        ("Initialization Tests", test_server_initialization), 
        ("Tool Definition Tests", test_tool_definitions),
        ("Tool Execution Tests", test_tool_execution),
        ("Tool Selection Tests", test_tool_selection),
        ("Dynamic Explorer Tests", test_dynamic_explorer),
        ("Claude Config Tests", test_claude_config),
        ("Pre-hook System Tests", test_pre_hook_system)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\n{'='*50}")
        print(f"Running: {test_name}")
        print('='*50)
        
        try:
            if asyncio.iscoroutinefunction(test_func):
                result = await test_func()
            else:
                result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"‚ùå {test_name} failed with exception: {e}")
            results.append((test_name, False))
    
    # Summary
    print(f"\n{'='*60}")
    print("üéØ TEST SUMMARY")
    print('='*60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"{status} {test_name}")
    
    print(f"\nüìä Results: {passed}/{total} tests passed ({passed/total*100:.1f}%)")
    
    if passed == total:
        print("\nüéâ ALL TESTS PASSED - 5-workflow architecture ready for deployment!")
        return True
    else:
        print(f"\n‚ö†Ô∏è  {total - passed} tests failed - please address issues before deployment")
        return False

if __name__ == "__main__":
    success = asyncio.run(run_all_tests())
    sys.exit(0 if success else 1)